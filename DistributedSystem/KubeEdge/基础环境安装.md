#### 1. 基础环境

操作系统：Ubuntu 22.04

工具：

* `netstat` sudo apt install net-tools
* `curl`
* `ntp`时间同步
* `openssl `

配置：系统配置网络IP

#### 2. 云原生基础

Centos8 docker image：  镜像，docker pull centos:centos8    验证，`cat /etc/os-release`。

`docker save -o hello-world.tar hello-world:latest`

> 表格中 - 号代表部分功能不支持、或者完全不支持

| Kubernetes version       | KubeEdge version | KubeVirt version | Rancher(RKE2) | Kubesphere(kk) |
| ------------------------ | ---------------- | ---------------- | ------------- | -------------- |
| 1.27、（**1.28**）、1.29 | 1.18             |                  | 2.8.x         | -              |
| （**1.26**）、1.27、1.28 | 1.17             |                  | 2.7.6         | 3.4.1-         |
| 1.25、（**1.26**）、1.27 | 1.16             |                  | 2.7.6         | 3.4.1-         |
| 1.23.x                   |                  |                  |               | 3.4.1          |

结论推荐Rancher、KK安装，支撑新版本-KubeEdge有更丰富的特性。

##### 2.1.离线安装

> 关闭SElinux

调研Rancher、KK安装，两者却别和差距，选择合理的部署方式。

> kubeadmin 安装注意事项:
>
> * 网络、端口打开和开放
> * Linux 禁用swap分区
> * HostName、MAC 唯一在不同节点

（1）KK安装系统

> KK 安装Kubesphere https://kubesphere.io/zh/docs/v3.4/installing-on-linux/introduction/air-gapped-installation/
>

（2）Rancher安装系统

**Rancher安装RKE2**

> Rancher安装K8s RKE2附带了containd，不需要安装docker
>

##### 2.2 安装Harbor

**On a Linux host:** docker 20.10.10-ce+ and docker-compose 1.18.0+ 、OpenSSL

> Harbor建议为HTTP请求，不要HTTPS，除非有公网证书认真，否则会出现错误。

```shell
# 0. 网桥设置，值为1则不用处理
sysctl net.bridge.bridge-nf-call-iptables # 查看命令

sudo vim /etc/sysctl.conf 
# 添加 net.bridge.bridge-nf-call-iptables = 1 
# 配置生效 sudo sysctl -p


mkdir -p /home/cetc15/tmp
cd /home/cetc15/tmp

# 1. 安装docker，拷贝所有deb文件到服务器文件夹
sudo dpkg -i *.deb
  
# 2.测试启动docker  
systemctl enable docker
sudo service docker start

docker load -i hello-world.tar
sudo docker run hello-world (可选)
 
# 3.安装docker-compose插件/usr/local/bin/docker-compose
mv docker-compose /usr/local/bin/docker-compose
chmod +777 /usr/local/bin/docker-compose

# 4.配置工具软连接（可选）
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose

# 5.解压Harbor offline
tar xzvf harbor-offline-installer-v2.11.1.tgz


# 6.修改Harbor 配置文件
cp harbor.yml.tmpl harbor.yml
hostname: IP
http.port: 5000
harbor_admin_password: 12345


# 7.执行安装
./install.sh --with-trivy


# 8.浏览器测试http://IP:5000/能否登录， admin/12345
# 9.配置docker仓库，并推送测试
vim /etc/docker/daemon.json
{
"insecure-registries" : ["IP:5000", "0.0.0.0","http://cetcharbor.com:5000"]
}

sudo systemctl daemon-reload
systemctl restart docker

docker login -u admin -p 12345 http://IP:5000
#  偶尔通过https不能访问，说明有些服务没有起来，通过docker-compose拉起来即可，常见为443端口未被映射
docker login -u admin -p 12345 cetcharbor.com


# 推送镜像测试
docker images
docker tag goharbor/harbor-exporter:v2.11.1 cetcharbor.com/goharbor/harbor-exporter:v2.11.1
# 推送前注意在harbor中创建库goharbor
docker push  cetcharbor.com/goharbor/harbor-exporter:v2.11.1


# 其他
systemctl restart docker
docker-compose down -v
docker-compose up -d
```

##### 2.3 安装过程

RKE2工具默认的安装位置`/var/lib/rancher/rke2/bin`

###### 2.3.1 Harbor镜像仓库安装

(1) 第一台机器安装

```shell
# 1. 将load-images.sh *.txt *.tar.gz 放在同一目录下,添加读、写、执行权限，在Harbor中创建rancher项目
./install-rke2-k8s-images.sh

# 2. 同样方法导入Rancher需要的镜像
# 3. 按照2.5、2.6配置文件
# 4. 安装rke2，过程如同2.3.2 Tarball安装，但不需要拷贝镜像文件，只需要rke2.linux-amd64.tar.gz和核心txt

# 5. 配置命令行访问工具
cp /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl
cp /var/lib/rancher/rke2/bin/crictl /usr/local/bin/crictl
sudo echo 'export KUBECONFIG=/etc/rancher/rke2/rke2.yaml' >> /etc/profile
sudo echo 'export IMAGE_SERVICE_ENDPOINT=unix:///run/k3s/containerd/containerd.sock' >> /etc/profile
sudo echo 'export CONTAINER_RUNTIME_ENDPOINT=unix:///run/k3s/containerd/containerd.sock'  >> /etc/profile
source /etc/profile

# 6. 验证工具
kubectl get pods -A   
```

（2）集群中机器安装

```shell
# 注意查看 2.5 配置文件与第一台不同

# 通2.3.2 安装，执行

# 验证，完成后，输入 kubectl get nodes -A ,可以看到其他节点

kubectl logs -n kube-system -l component=kube-apiserver  查看label 为 component=kube-apiserver的容器日志
```

###### 2.3.2 Tarball安装

> （1）Tarball 安装，安装程序可能不识别 rke2-images.linux-amd64.tar.gz，需要解压为 rke2-images.linux-amd64.tar 
>
> ​		gzip -dc rke2-images.linux-amd64.tar.gz > rke2-images.linux-amd64.tar
>
> （2）zst压缩文件无限制

```shell
sudo -i #1.切换到root用户
mkdir -p /var/lib/rancher/rke2/agent/images/ #2.创建目录
chmod +777 /var/lib/rancher/rke2/agent/images/ #3.修改权限
# 4.拷贝安装包到目录
# 5.修改安装包执行权限
# 6.移动解压rke2.linux-amd64 到/usr/local/bin/rke2
tar xzf /var/lib/rancher/rke2/agent/images/rke2.linux-amd64.tar.gz -C /usr/local
# 7.移动service文件到systemd
mv -f /usr/local/lib/systemd/system/rke2-*.service /etc/systemd/system/
# 8.检测service服务启动 systemctl status rke2-server.service
systemctl daemon-reload
# 9.服务启动
systemctl enable rke2-server.service
systemctl start rke2-server.service
# 10.查看安装日志
journalctl -u rke2-server -f
# 11.镜像安装进程查看
journalctl -xeu rke2-server.service | grep tar.gz


# 其他配置
mkdir -p /etc/rancher/rke2/
chmod +777 /etc/rancher/rke2/
/etc/rancher/rke2/config.yaml
```

##### 2.4 卸载环境

```shell
# 切换root用户
./usr/local/bin/rke2-killall.sh
./usr/local/bin/rke2-uninstall.sh

# 清理docker所有没有使用的镜像
docker image prune -a
```

##### 2.5 RKE2安装配置

把 config.yaml 文件创建到 `/etc/rancher/rke2/config.yaml` 中。这将包含创建高可用 RKE2 集群所需的所有配置选项。

第一台服务器的最低配置是：

```yaml
token: my-shared-secret
tls-san:
  - loadbalancer-dns-domain.com
```

其他服务器的配置文件应该包含相同的令牌，并让 RKE2 知道要连接到现有的第一台服务器：

```yaml
server: https://ip-of-first-server:9345
token: my-shared-secret
tls-san:
  - loadbalancer-dns-domain.com
```

##### 2.6 RKE2镜像地址配置(optional)

把 `registries.yaml` 文件创建到 `/etc/rancher/rke2/registries.yaml` 中。此文件为 RKE2 提供连接到你的私有镜像仓库的详细信息。

在加入必要信息之前，`registries.yaml` 文件是这样的：

```yaml
---
mirrors:
  customreg:
    endpoint:
      - "https://ip-to-server:5000"
configs:
  customreg:
    auth:
      username: xxxxxx # 镜像仓库的用户名
      password: xxxxxx # 镜像仓库的密码
    tls:
      cert_file: /data/cert/cetcharbor.com.cert
      key_file: /data/cert/cetcharbor.com.key
      ca_file: /data/cert/ca.crt
```

Harbor证书拷贝：

```
ca.crt    >    /data/cert/
cetcharbor.com.crt   >   /data/cert/
cetcharbor.com.key   >   /data/cert/
```

#### 3. 集成安装Helm

RKE2 helm 清单： https://docs.rke2.io/zh/helm#%E4%BD%BF%E7%94%A8-helm-crd

RKE2 helm Chart 仓库：https://github.com/rancher/rke2-charts/tree/main/charts

```shell
# 1. 解压
tar -zxvf helm-v3.15.4-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm

# 2. 验证
helm help
```

##### 3.1 Helm执行命令

 ```shell
# 1. 添加仓库
helm repo add jetstack https://charts.jetstack.io
helm repo update
# 2. 远程拉取镜像
helm fetch jetstack/cert-manager
helm template ./cert-manager-<version>.tgz | awk '$1 ~ /image:/ {print $2}' | sed s/\"//g >> ./rancher-images.txt
# 3. 查看已经部署的镜像
helm list
helm list --all 展示所有release，包括失败的条目
helm list -n xxx
# 4. 安装、卸载镜像
helm install xxx    (helm install happy-panda bitnami/wordpress 给 bitnami/wordpress 起名字为 happy-panda )
helm uninstall xxx
helm status xxx
helm delete xxx
# 5. 查看帮助信息
helm get -h
 ```

##### 3.2 helm高级命令

```shell
# 1. 搜索，从 Artifact Hub 中查找并列出 helm charts
helm search hub xxx 
# 2. 使用 helm repo add 到本地 helm 客户端中的仓库中进行查找
helm search repo xxx
# 3. 使用 helm show values 可以查看 chart 中的可配置选项
helm show values xxx
# 4. chart 升级
helm upgrade -f panda.yaml happy-panda bitnami/wordpress
```

##### 3.3 更改配置，启动chart

```shell
echo '{mariadb.auth.database: user0db, mariadb.auth.username: user0}' > values.yaml
helm install -f values.yaml bitnami/wordpress --generate-name

上述命令将为 MariaDB 创建一个名称为 user0 的默认用户，并且授予该用户访问新建的 user0db 数据库的权限。chart 中的其他默认配置保持不变。

安装过程中有两种方式传递配置数据：

--values (或 -f)：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。
--set：通过命令行的方式对指定项进行覆盖。

--set name=value   等同于 name: value 
```

##### 3.4 本地安装包


* 本地 chart 压缩包（helm install foo foo-0.1.1.tgz）
* 解压后的 chart 目录（helm install foo path/to/foo）
* 完整的 URL（helm install foo https://example.com/charts/foo-1.2.3.tgz）

#### 4. Rancher安装

```shell
# 1. 将rancher镜像导入私有镜像库
# 2. 拷贝cert-manager、rancher chart和cert-manager-crd.yaml,文件到Linux系统
# 3. 通过Helm安装cert-manager chart, 保证SSL安全
# <1> 创建namespace
kubectl create namespace cert-manager
# <2> 创建 cert-manager CustomResourceDefinition
kubectl apply -f cert-manager-crd.yaml
# <3> 安装cert-manager
helm install cert-manager ./cert-manager-v1.15.3.tgz \
    --namespace cert-manager \
    --set image.repository=cetcharbor.com/quay.io/jetstack/cert-manager-controller \
    --set webhook.image.repository=cetcharbor.com/quay.io/jetstack/cert-manager-webhook \
    --set cainjector.image.repository=cetcharbor.com/quay.io/jetstack/cert-manager-cainjector \
    --set startupapicheck.image.repository=cetcharbor.com/quay.io/jetstack/cert-manager-startupapicheck
# <4> 查询证书签发
kubectl get certificate -A

# 4. 通过helm安装Rancher
# <1> 自创建rancher需要的ssl，自动创建不需要操作
kubectl -n cattle-system create secret tls tls-rancher-ingress \
  --cert=tls.crt \
  --key=tls.key
  
kubectl -n cattle-system delete secret tls-rancher-ingress


# <2> Helm chart创建
kubectl create namespace cattle-system

# replicas设置高可用，一般为3
helm install rancher ./rancher-2.9.1.tgz \
    --namespace cattle-system \
    --set hostname=rancher.cetc.com \
    --set certmanager.version=1.15.3 \
    --set bootstrapPassword=admin@123456 \
    --set rancherImage=cetcharbor.com/rancher/rancher \
    --set systemDefaultRegistry=cetcharbor.com \
    --set replicas=1 \
    --set useBundledSystemChart=true


# <3> 查看密码
kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ "\n" }}'
```



#### 5. K8s的可视化界面:

* 容器监控工具WeaveScope
* OKD Web控制台
* Dashbards
* Platform9

#### 6.  其他

##### 6.1 制作可导入镜像库的元数据

```shell
# 1. 镜像压缩包，docker pull xxx 下载镜像到docker
# 2. 将镜像压入一个镜像包中
docker save <Image-List....> | gzip --stdout > xxxx.tar.gz
# 样例
docker save quay.io/jetstack/cert-manager-startupapicheck:v1.15.3 quay.io/jetstack/cert-manager-webhook:v1.15.3 | gzip --stdout > rancher-2.9.1.tar.gz

# 3. 根据镜像目录编写.txt文件

# 4. 脚本导入
```

##### 6.2 docker清理

```shell
# 1.清理未被使用的镜像
docker image prune -a

# 2.清理本地缓存
docker system prune
```





